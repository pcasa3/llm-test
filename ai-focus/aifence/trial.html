        <div class="sidebar">
               <h3>AI-FOCUS AI安全围栏测试说明</h3>
               1.邮箱申请：每个邮箱点击申请，可以获得token,token 20分钟内有效<br>
               2.使用我方提供的LLM API，每个邮箱可以测试20次<br>
               3.您可以使用自己的LLM API测试，每个邮箱可以测试40次；我们不会记录您的LLM API key,但为安全起见，请您使用临时KEY测试，测试完毕后删除临时KEY<br>
               4.Demo支持2类的LLM API，一类是OPENAI兼容模式，需要填写API的BASE URL（不要带/chat/completions,到/v1、/v2、/v3这样的就结束）、API KEY、模型名；一类是Gemini兼容模型，需要填写API KEY、模型名<br>
               5.AI安全围栏DEMO主要是演示拦截2类风险，一类是违规内容、一类是隐私数据泄露，可以输入时识别到风险进行拦截（如提示词攻击），有些攻击输入做了对抗识别不到，也可以根据AI输出的内容识别到风险进行拦截，测试用例指导：<br>
                a) 敏感数据泄露测试：模型内置了一个总经理的电话号码，您可以关闭AI安全围栏，然后询问AI模型总经理的电话，AI模型会输出手机号码；打开AI安全围栏，然后询问AI模型总经理的电话，AI再输处时会识别到风险进行拦截。<br>
                b) 违规话题输入拦截：您可以询问AI一些违规话题，如果关闭AI安全围栏，有些模型会输出违规内容，有些模型会拒绝回答；打开AI安全围栏，询问AI一些违规话题，AI电子护栏会直接拦截违规内容。<br>
                c) 专业提示词攻击拦截：您如果对提示词攻击有了解，可以采用多种提示词攻击方法（包括不限于特殊句式构造、场景欺骗、形式化符号攻击、子词融合攻击、聚类词、池化攻击、GCG等），并对违规关键字进行对抗处理（如字直接增加符号隔断），如果关闭AI安全围栏，很多模型会输出违规内容或敏感内容（如学习和搜索到的名人的隐私数据）；打开AI安全围栏，采用同样的攻击，如果没有对违规关键字做了对抗处理，AI电子护栏会输入时识别直接拦截；如果对违规关键字做了对抗处理，90%以上的攻击，AI电子护栏会在输出识别直接拦截；<br>
               <iframe src="http://114.55.15.177:8008/" title="产品试用" height=6000></iframe>
        </div>